
n = 25; % number of samples
d = 10; % input space dimensionality
% k = 10000; % embedding space dimensionality

% Aim is to approximate a linear kernel
% X = randn(d,n);
X = ...
   [0.7832    1.2722   -0.7392    1.0125   -0.5166   -1.7902   -0.0405   -0.1380    3.6953    1.3312    0.4674    1.0917    0.3598    0.5825   -0.3234    0.0237    0.3502    1.1720    1.2841    0.0606    0.2739   -0.0766   -0.8944   -0.2980   -0.2120;
   -0.3917    0.0390   -0.9696    0.7759    0.1503   -0.3946    1.4460    1.7904    0.7039   -0.2959   -0.7484    0.9258    1.1041   -0.3075   -1.2707   -0.0757   -1.2588   -1.1348    0.7606   -1.1588   -1.7229    0.9328   -0.8394    0.0487   -0.2951;
    0.4676   -0.6220    0.6016   -1.2425   -0.4559   -0.5176   -0.5459    0.2487    0.3824   -0.3401    0.8921   -1.0241   -0.1688   -0.2731   -0.5397    0.4708    0.8971   -0.5732    0.2780    0.4139   -0.9349   -2.2040    0.8927   -0.1725    0.3755;
    0.4539   -2.0851   -0.5522    0.0114   -0.7019    1.3585    0.5731    0.6748    0.2072    1.3283    1.2124    0.5269   -0.2416   -0.7360    0.9278    0.1791    0.4946    0.7702   -0.4865    0.6145    2.0150    3.1555    1.3209    0.1458   -0.6439;
    0.5132   -0.2693   -1.6352    0.9116   -1.0928   -0.8719    0.6756   -0.0058    1.8590   -0.2743    0.7361   -0.3908    1.0104   -1.2331    0.1614   -1.3100    1.0315   -1.2622    0.4752   -0.1804    1.5850   -0.1895   -0.5894   -1.3855   -0.3294;
    0.0952    0.2019   -1.2017   -1.6508    0.7478   -0.4882    1.0743   -0.2862    0.9590   -1.2744    3.3222    1.1735   -2.0597   -0.4550   -0.9825    1.0117    0.3584   -1.2106    0.5364   -1.4812   -0.8599    0.2943    1.1507   -1.3799    1.2049;
   -0.9261   -0.2313   -1.8657   -0.5591   -0.2977    0.6166    1.2716    0.8845    1.3604    0.3475    0.0221   -0.4749   -0.7684    0.0961   -0.8901   -0.7973   -0.3927    1.5487    0.8204   -0.8597   -0.2141    1.9429   -1.3695    1.4851   -0.9241;
   -0.4920    1.0148    0.7211    0.3302    0.2317   -2.3643   -0.0340    1.3523    0.3514    0.3626    1.4019   -0.6949    0.1966   -0.7096   -1.6821    0.7778   -2.4533    0.9329   -0.5156   -1.7617    1.4499    0.5327   -1.0023    0.8587    0.4608;
    0.9114    0.7777    1.2953    0.0607   -0.8540    1.9378   -0.5431   -0.8159   -1.9033    1.2149   -1.3264    0.3271   -1.5510   -0.6242    1.5347   -1.0559   -0.5543   -0.9658   -1.2648    0.6122    1.5263    0.3107    0.1099   -1.1802   -1.4937;
   -0.1146   -0.5232    0.3694    0.0146    1.8325    0.6620    0.5606   -1.7088    1.3448    0.1951   -1.5425   -0.7235   -0.1529    1.3353   -1.5948   -1.3390    0.1149   -0.7745   -0.4364   -0.6045    1.9477    1.7257    0.3311    1.2968   -0.8311];


k_list = 4 .^ [0:5];
% k_list = 10 .^ [0:3];

i = 1;
figure,

for k = k_list

  Psi = 1/sqrt(k) * randn(k, d);
  subplot(numel(k_list), 4, i);
  i = i + 1;
  imagesc(Psi' * Psi), colorbar,
  title(sprintf('N(0,1) (k = %d) - Delta w/ eye(): %.4f', k, norm(Psi' * Psi - eye(d), 'fro')));


  Psi = 1/sqrt(k) * sign(randn(k, d));
  subplot(numel(k_list), 4, i);
  i = i + 1;
  imagesc(Psi' * Psi), colorbar,
  title(sprintf('{-1,+1} (k = %d) - Delta w/ eye(): %.4f', k, norm(Psi' * Psi - eye(d), 'fro')));


  [~, Psi, ~, ~] = getApproximateRBFKernel(1:d, 1:d, 10e-10, k);
  subplot(numel(k_list), 4, i);
  i = i + 1;
  imagesc(Psi' * Psi), colorbar,
  title(sprintf('RPCA_1 (k = %d) - Delta w/ eye(): %.4f', k, norm(Psi' * Psi - eye(d), 'fro')));


  [Psi, ~, K_approx] = getApproximateLinearKernel(X, k);
  subplot(numel(k_list), 4, i);
  i = i + 1;
  imagesc(Psi' * Psi), colorbar,
  title(sprintf('RPCA_2 (k = %d) - Delta w/ eye(): %.4f', k, norm(Psi' * Psi - eye(d), 'fro')));

end
